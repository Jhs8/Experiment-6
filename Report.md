# SRCNN实验报告

考虑一个单一低分辨率图像，我们首先使用双三次插值将其放大到所需的大小，这是我们进行的唯一预处理。我们将插值后的图像表示为Y。我们的目标是从Y中恢复出一个图像F(Y)，使其尽可能地与真实高分辨率图像X相似。为了方便表达，我们仍然将Y称为“低分辨率”图像，尽管它的大小与X相同。我们希望学习一个映射F，它在概念上包括三个操作：

1. **Patch提取和表示：** 该操作从低分辨率图像Y中提取（重叠的）补丁，并将每个补丁表示为高维向量。这些向量组成一组特征图，其数量等于向量的维度。
2. **非线性映射：** 该操作将每个高维向量非线性映射到另一个高维向量。每个映射的向量在概念上是高分辨率补丁的表示。这些向量构成另一组特征图。
3. **重建：** 该操作聚合上述高分辨率补丁的表示，生成最终的高分辨率图像。这个图像预期与地面真实的X相似。

我们将展示所有这些操作形成一个卷积神经网络。网络的概览如图所示。接下来，我们详细介绍每个操作的定义。

## 3.1.1 Patch提取和表示

在图像恢复中的一种流行策略是密集地提取补丁，然后用一组预训练的基础（如PCA、DCT、Haar等）表示它们。这等效于通过一组滤波器卷积图像，其中每个滤波器是一种基础。在我们的公式中，我们将这些基础的优化纳入网络的优化中。形式上，我们的第一层表示为操作F1：

$$
F1(Y) = \max(0, W1 * Y + B1)
$$

其中W1和B1分别表示滤波器和偏差，'*'表示卷积操作。这里，W1对应于支持$c×f1×f1$的n1个滤波器，其中c是输入图像的通道数，$f1$是滤波器的空间尺寸。直观地说，$W1$在图像上应用n1次卷积，每个卷积具有内核大小$c×f1×f1$。输出由n1个特征图组成。B1是一个n1维向量，其每个元素与一个滤波器相关联。我们在滤波器响应上应用修正线性单元（ReLU，$\max(0, x)$）。

## 3.1.2 非线性映射

第一层为每个补丁提取了一个n1维特征。在第二操作中，我们将这些n1维向量中的每一个映射到一个n2维向量。这等效于应用n2个具有平凡空间支持1×1的滤波器。这种解释仅对于1×1滤波器有效。但是很容易推广到更大的滤波器，如3×3或5×5。在这种情况下，非线性映射不是在输入图像的一个补丁上进行的；相反，它是在特征图的一个3×3或5×5“补丁”上进行的。第二层的操作是：

$$
F2(Y) = \max(0, W2 * F1(Y) + B2)
$$

这里W2包含n2个大小为n1×f2×f2的滤波器，B2是n2维的。每个输出的n2维向量在概念上是一个高分辨率补丁的表示，将用于重建。

## 3.1.3 重建

在传统方法中，通常对预测的重叠高分辨率补丁进行平均以生成最终的完整图像。平均可以被认为是一组特征图上的预定义滤波器（其中每个位置是高分辨率补丁的“平坦”向量形式）。受此启发，我们定义一个卷积层来生成最终的高分辨率图像：

$$
F(Y) = W3 * F2(Y) + B3
$$

这里W3对应于c个n2×f3×f3大小的滤波器，B3是一个c维向量。如果高分辨率补丁的表示在图像域中（即，我们可以简单地重塑每个表示以形成补丁），我们期望滤波器的作用类似于平均滤波器；如果高分辨率补丁的表示在其他领域（例如，一些基的系数方面），我们期望W3的行为类似于首先将系数投影到图像域，然后进行平均。无论哪种方式，W3都是一组线性滤波器。

有趣的是，尽管上述三个操作受到不同直觉的启发，它们都导致与卷积层相同的形式。我们将所有三个操作放在一起，并形成一个卷积神经网络。在这个模型中，所有滤波权重和偏差都将被优化。

## 3.2 与基于稀疏编码的方法的关系

我们表明基于稀疏编码的SR方法[49]，[50]可以看作是一个卷积神经网络。图3显示了一个说明。

在基于稀疏编码的方法中，我们考虑从输入图像中提取一个f1 × f1的低分辨率补丁。然后，稀疏编码求解器，如Feature-Sign [29]，将首先将补丁投影到（低分辨率）字典上。如果字典大小为n1，这相当于在输入图像上应用n1个线性滤波器（f1 × f1）（均值减法也是线性操作，因此可以吸收）。这在图3的左侧部分有图示。

稀疏编码求解器然后迭代处理n1个系数。该求解器的输出是n2个系数，通常在稀疏编码的情况下n2 = n1。这n2个系数是高分辨率补丁的表示。在这个意义上，稀疏编码求解器表现为一种空间支持为1×1的非线性映射操作符的特殊情况。见图3的中间部分。然而，稀疏编码求解器不是前馈的，即它是一个迭代算法。相反，我们的非线性操作符是完全前馈的，可以高效计算。如果设置f2 = 1，那么我们的非线性操作符可以被视为逐像素的全连接层。值得注意的是，在SRCNN中，“稀疏编码求解器”指的是前两层，而不仅仅是第二层或激活函数（ReLU）。因此，SRCNN中的非线性操作也经过了良好的优化学习过程。

上述n2个系数（经过稀疏编码后）然后投影到另一个（高分辨率）字典上，以生成高分辨率补丁。然后对重叠的高分辨率补丁进行平均。如上所述，这相当于对n2个特征图进行线性卷积。如果用于重建的高分辨率补丁的大小为f3 × f3，则线性滤波器具有等效的空间支持大小为f3 × f3。见图3的右侧部分。

上述讨论表明，基于稀疏编码的SR方法可以看作是一种卷积神经网络（具有不同的非线性映射）。但并没有在稀疏编码的SR方法的优化中考虑所有操作。相反，在我们的卷积神经网络中，低分辨率字典、高分辨率字典、非线性映射，以及均值减法和平均值都涉及到要优化的滤波器。因此，我们的方法优化了一个包含所有操作的端到端映射。

这种类比还可以帮助我们设计超参数。例如，我们可以将最后一层的滤波器大小设置为小于第一层的大小，因此我们更多地依赖于高分辨率补丁的中心部分（极端情况下，如果f3 = 1，我们使用中心像素而不进行平均）。我们还可以设置n2 < n1，因为预计它将更稀疏。一个典型且基本的设置是f1 = 9，f2 = 1，f3 = 5，n1 = 64，n2 = 32（在实验部分我们评估了更多的设置）。总体上，估计高分辨率像素利用(9 + 5 − 1)² = 169个像素的信息。显然，用于重建的信息相对于现有的外部基于示例的方法要更大，例如使用(5+5−1)² = 81像素[15]，[50]。这是SRCNN表现卓越的原因之一。

## 3.3 训练

学习端到端映射函数F需要估计网络参数Θ = {W1，W2，W3，B1，B2，B3}。这通过最小化重建图像F(Y; Θ)与相应的地面真实高分辨率图像X之间的损失来实现。给定一组高分辨率图像{Xi}及其相应的低分辨率图像{Yi}，我们使用均方误差（MSE）作为损失函数：

$$
L(\Theta) = \frac{1}{n} \sum_{i=1}^{n} \|F(Y_i; \Theta) - X_i\|_2^2
$$

这里n是训练样本的数量。使用MSE作为损失函数有利于获得高峰值信噪比（PSNR）。PSNR是用于定量评估图像恢复质量的广泛使用的指标，与感知质量至少部分相关。值得注意的是，卷积神经网络不排除使用其他类型的损失函数，只要这些损失函数是可导的。如果在训练过程中给出了更好的感知度量，网络可以灵活地适应该度量。相反，对于传统的“手工制作”方法来说，通常难以实现这种灵活性。

损失通过标准反向传播进行随机梯度下降最小化[28]。具体地，权重矩阵的更新如下：

$$
\Delta_{i+1} = 0.9 \cdot \Delta_i - \eta \cdot \frac{\partial L}{\partial W_i'}, \quad W_i' = W_i + \Delta_{i+1}
$$

这里` ∈ {1, 2, 3}和i是层和迭代的索引，η是学习速率，$\frac{\partial L}{\partial W_i'}$是导数。

每一层的滤波权重通过从均值为零、标准差为0.001的高斯分布中随机抽取进行初始化（偏差为0）。前两层的学习速率为10⁻⁴，最后一层为10⁻⁵。我们经验性地发现，对于网络收敛来说，最后一层的学习速率较小是重要的（类似于去噪的情况[22]） 。

在训练阶段，地面真实图像{Xi}被准备为从训练图像中随机裁剪的fsub×fsub×c像素子图。通过“子图像”我们指的是这些样本被视为小的“图像”，而不是“补丁”，在这个意义上，“补丁”是重叠的，并需要一些平均作为后处理，但“子图像”不需要。为了合成低分辨率样本{Yi}，我们通过高斯核对子图像进行模糊，通过下采样以达到放大因子，然后通过双三次插值进行放大。

为了在训练期间避免边界效应，所有卷积层都没有填充，网络产生较小的输出（(fsub − f1 − f2 − f3 + 3)² × c）。MSE损失函数仅通过Xi的中心像素与网络输出之间的差异来评估。尽管在训练中使用了固定的图像大小，但卷积神经网络在测试期间可以应用于任意大小的图像。

我们使用cuda-convnet软件包[26]实现了我们的模型。我们还尝试了Caffe软件包[24]并观察到类似的性能。


# 4 实验

首先，我们研究使用不同数据集对模型性能的影响。接下来，我们研究我们方法学习到的滤波器。然后，我们探索网络的不同架构设计，并研究超分辨率性能与深度、滤波器数量和滤波器大小等因素之间的关系。随后，我们在定量和定性上将我们的方法与最近的最先进方法进行比较。根据[42]，在4.1-4.4节，超分辨率仅应用于亮度通道（YCbCr色彩空间中的Y通道），因此第一/最后一层的c = 1，性能（例如PSNR和SSIM）在Y通道上评估。最后，我们将网络扩展到处理彩色图像，并在不同通道上评估性能。

## 4.1 训练数据

如文献中所示，深度学习通常受益于大规模的训练数据。为了比较，我们使用相对较小的训练集[41]，[50]，其中包含91个图像，以及包含395,909个图像的大型训练集，这些图像来自ILSVRC 2013 ImageNet检测训练分区。训练子图像的大小为fsub = 33。因此，91个图像数据集可以分解为24,800个子图像，这些子图像从原始图像中以14的步长提取而来。而ImageNet即使使用步长为33仍提供超过5百万的子图像。我们使用基本网络设置，即f1 = 9，f2 = 1，f3 = 5，n1 = 64，n2 = 32。我们使用Set5 [2]作为验证集。我们观察到即使使用更大的Set14集[51]，趋势也是相似的。放大因子为3。我们使用基于稀疏编码的方法[50]作为基线，其平均PSNR值为31.42 dB。

使用不同训练集的测试收敛曲线如图4所示。在ImageNet上的训练时间与91图像数据集上的时间相同，因为反向传播的次数相同。可以观察到，使用相同次数的反向传播（即8 × 10⁸），SRCNN+ImageNet的PSNR达到了32.52 dB，高于在91图像上训练的32.39 dB。这些结果积极地表明，使用更大的训练集可以进一步提高SRCNN的性能，但大数据的效果并不像在高级别视觉问题中所显示的那样令人印象深刻[26]。这主要是因为这91张图像已经捕捉到足够的自然图像的变化性。另一方面，我们的SRCNN是一个相对较小的网络（8,032个参数），不能过度拟合这91张图像（24,800个样本）。然而，在后续实验中，我们采用包含更多不同数据的ImageNet作为默认的训练集。

## 4.2 用于超分辨率的学习滤波器

图5显示了在ImageNet上通过3倍放大因子训练的学习到的第一层滤波器的示例。请参考我们已发布的实现，以获取2倍和4倍放大因子的结果。有趣的是，每个学习到的滤波器都有其特定的功能。例如，滤波器g和h类似于Laplacian/Gaussian滤波器，滤波器a-e类似于不同方向的边缘检测器，而滤波器f类似于纹理提取器。不同层的示例特征图显示在图6中。显然，第一层的特征图包含不同的结构（例如，不同方向的边缘），而第二层的主要区别在于强度。

## 4.3 模型和性能权衡

基于基本网络设置（即f1 = 9，f2 = 1，f3 = 5，n1 = 64，n2 = 32），我们将逐渐修改其中一些参数，以研究性能和速度之间的最佳权衡，并研究性能与参数之间的关系。

### 4.3.1 滤波器数量

一般来说，如果我们增加网络的宽度，即添加更多的滤波器，性能会提高，但运行时间会增加。具体来说，基于我们网络的默认设置，即n1 = 64和n2 = 32，我们进行两个实验：（i）一个具有更大网络的实验，其中n1 = 128和n2 = 64，（ii）另一个具有更小网络的实验，其中n1 = 32和n2 = 16。与4.1节类似，我们还在ImageNet上训练两个模型，并在Set5上进行放大因子为3的测试。在8 × 10⁸次反向传播时观察到的结果如表1所示。显然，通过增加宽度可以实现更好的性能。但是，如果需要快速恢复速度，建议选择较小的网络宽度，这仍然可以实现比基于稀疏编码的方法（31.42 dB）更好的性能。

### 4.3.2 滤波器大小

在本节中，我们研究网络对不同滤波器大小的敏感性。在先前的实验中，我们设置了滤波器大小f1 = 9，f2 = 1和f3 = 5，网络可以表示为9-1-5。首先，为了与基于稀疏编码的方法保持一致，我们固定第二层的滤波器大小为f2 = 1，并将其他层的滤波器大小扩大到f1 = 11和f3 = 7（11-1-7）。所有其他设置与4.1节相同。在Set5上进行3倍放大的结果为32.57 dB，略高于4.1节中报告的32.52 dB。这表明，相对较大的滤波器大小可以捕获更丰富的结构信息，从而产生更好的结果。

然后，我们进一步研究具有更大第二层滤波器大小的网络。具体来说，我们固定滤波器大小f1 = 9，f3 = 5，并将第二层的滤波器大小扩大到（i）f2 = 3（9-3-5）和（ii）f2 = 5（9-5-5）。图7中的收敛曲线显示，使用更大的滤波器大小可以显著提高性能。具体而言，通过8 × 10⁸次反向传播在Set5上实现的9-3-5和9-5-5的平均PSNR值分别为32.66 dB和32.75 dB。结果表明，在映射阶段利用邻域信息是有益的。

然而，使用较大的滤波器大小部署速度也会减慢。例如，9-1-5、9-3-5和9-5-5的参数数量分别为8,032、24,416和57,184。9-5-5的复杂性几乎是9-3-5的两倍，但性能提升较小。因此，网络规模的选择始终应该是性能和速度之间的权衡。
